{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from utils.conn_data import load_pickle\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_path = os.path.join(os.getcwd(), 'data', 'outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation 1a\n",
    "\n",
    "### Dataset\n",
    "\n",
    "For each covariance in a list of different covariances between graph pairs, we simulate 30 times (n_simulations) a list of 50 (n_graphs) pairs of graphs from the erdos-renyi family of graphs. For each pair of graph, we sample a random variable p from a multivariate gaussian distribution with fixed mean and covariance.\n",
    "\n",
    "### Model\n",
    "\n",
    "1) $\\textbf{Spectrum}$: For each pair of graphs, compute the spectral radii for each adjacency matrix individually, and compute the Spearman's rank correlation between the spectral radiis for each graph.\n",
    "\n",
    "2) $\\textbf{SDNE}$: For each epoch, for each pair of graphs, compute the embeddings using the SDNE (autoencoder), and compute the Spearman's rank correlation between the vectorial version of the embeddings of each graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = \"simulation1a\"\n",
    "# models = os.listdir(os.path.join(outputs_path, dataset))\n",
    "# all_test_data = []\n",
    "# agg_metrics = []\n",
    "# all_metrics_by_true_cov = []\n",
    "# all_diff_by_true_cov = []\n",
    "# for model in models:\n",
    "\n",
    "#     if 'spectrum' in model:\n",
    "#         data = load_pickle(os.path.join(outputs_path, dataset, model, 'results.pkl'))\n",
    "#         test_data = data[\"train_test_results\"]\n",
    "#     else:\n",
    "#         data = load_pickle(os.path.join(outputs_path, dataset, model, 'predictions.pkl'))\n",
    "#         test_data = data[\"test_predictions\"]\n",
    "\n",
    "#     if len(test_data.shape) > 2:\n",
    "#         test_data_df = []\n",
    "#         for i in range(test_data.shape[0]):\n",
    "#             simulation_test_data = test_data[i, :, :]\n",
    "#             simulation_test_data_df = pd.DataFrame(simulation_test_data.numpy(), columns=[\"pred\", \"true\"])\n",
    "#             simulation_test_data_df.loc[:, \"simulation\"] = i\n",
    "\n",
    "#             test_data_df.append(simulation_test_data_df)\n",
    "#         test_data_df = pd.concat(test_data_df, axis=0)\n",
    "#         test_data_df.loc[:, \"true\"] = [round(x, 2) for x in test_data_df[\"true\"]]\n",
    "#         test_data_df.loc[:, \"model\"] = model\n",
    "#     else:\n",
    "#         test_data_df = pd.DataFrame(test_data.numpy(), columns=[\"pred\", \"true\"])\n",
    "#         test_data_df.loc[:, \"true\"] = [round(x, 2) for x in test_data_df[\"true\"]]\n",
    "#         test_data_df.loc[:, \"model\"] = model\n",
    "#     all_test_data.append(test_data_df)\n",
    "\n",
    "#     # compute aggregated mse and mae\n",
    "#     mse = mean_squared_error(test_data_df[\"true\"], test_data_df[\"pred\"])\n",
    "#     mae = mean_absolute_error(test_data_df[\"true\"], test_data_df[\"pred\"])\n",
    "#     agg_metrics.append({\"model\": model, \"mse\": mse, \"mae\": mae})\n",
    "\n",
    "#     # compute mse and mae per true cov\n",
    "#     metrics_by_true_cov = []\n",
    "#     for cov in test_data_df[\"true\"].unique():\n",
    "#         selected_df = test_data_df.loc[test_data_df[\"true\"] == cov]\n",
    "\n",
    "#         pred = selected_df[\"pred\"]\n",
    "#         true = selected_df[\"true\"]\n",
    "\n",
    "#         mse = mean_squared_error(true, pred)\n",
    "#         mae = mean_absolute_error(true, pred)\n",
    "#         metrics_by_true_cov.append({\"model\": model, \"dataset\": dataset, \"cov\": cov, \"mse\": mse, \"mae\": mae})\n",
    "#     metrics_by_true_cov_df = pd.DataFrame(metrics_by_true_cov)\n",
    "#     all_metrics_by_true_cov.append(metrics_by_true_cov_df)\n",
    "\n",
    "#     # compute diff by true cov\n",
    "#     diff_by_true_cov = []\n",
    "#     for cov in test_data_df[\"true\"].unique():\n",
    "#         selected_df = test_data_df.loc[test_data_df[\"true\"] == cov]\n",
    "\n",
    "#         pred = selected_df[\"pred\"]\n",
    "#         true = selected_df[\"true\"]\n",
    "\n",
    "#         selected_df.loc[:, \"diff\"] = true - pred\n",
    "#         diff_by_true_cov.append(selected_df)\n",
    "#     diff_by_true_cov_df = pd.concat(diff_by_true_cov, axis=0)\n",
    "#     all_diff_by_true_cov.append(diff_by_true_cov_df)\n",
    "\n",
    "# all_test_data_df = pd.concat(all_test_data, axis=0)\n",
    "# agg_metrics_df = pd.DataFrame(agg_metrics)\n",
    "# all_metrics_by_true_cov_df = pd.concat(all_metrics_by_true_cov, axis=0)\n",
    "# all_diff_by_true_cov_df = pd.concat(all_diff_by_true_cov, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_agg_metrics = []\n",
    "# for idx, row in agg_metrics_df.iterrows():\n",
    "#    model = row[\"model\"].split(\"_\")[0]\n",
    "   \n",
    "#    if model.startswith(\"spectrum\"):\n",
    "#        parse_agg_metrics.append({\"model\": model,\n",
    "#                                  \"mse\": row[\"mse\"],\n",
    "#                                  \"mae\": row[\"mae\"]})\n",
    "#    elif model.startswith('sae'):\n",
    "#         #model_name = f'{args.model_name}_{hidden_sizes_str}_{sparsity_penalty_scaled}_{dropout_scaled}_{int(args.epochs)}'\n",
    "#         epochs = row[\"model\"].split(\"_\")[-1]\n",
    "#         dropout = row[\"model\"].split(\"_\")[-2]\n",
    "#         sparsity = row[\"model\"].split(\"_\")[-3]\n",
    "#         hidden_layers = row[\"model\"].split(\"_\")[1:-4]\n",
    "\n",
    "#         parse_agg_metrics.append({\"model\": model,\n",
    "#                                   \"dropout\": dropout,\n",
    "#                                   \"sparsity\": sparsity,\n",
    "#                                   \"hidden_layers\": str(hidden_layers),\n",
    "#                                   \"epochs\": epochs,\n",
    "#                                   \"mse\": row[\"mse\"],\n",
    "#                                   \"mae\": row[\"mae\"]}\n",
    "#                                 )\n",
    "\n",
    "#    elif model.startswith(\"sdne\") or model.startswith(\"sgnn0\"):\n",
    "#          n_hidden = row[\"model\"].split(\"_\")[1]\n",
    "#          n_layers_enc = row[\"model\"].split(\"_\")[2]\n",
    "#          n_layers_dec = row[\"model\"].split(\"_\")[3]\n",
    "#          epochs = row[\"model\"].split(\"_\")[4]\n",
    "#          parse_agg_metrics.append({\"model\": model,\n",
    "#                                    \"n_hidden\": n_hidden,\n",
    "#                                    \"n_layers_enc\": n_layers_enc,\n",
    "#                                    \"n_layers_dec\": n_layers_dec,\n",
    "#                                    \"epochs\": epochs,\n",
    "#                                    \"mse\": row[\"mse\"],\n",
    "#                                    \"mae\": row[\"mae\"]})\n",
    "#    else:\n",
    "#        raise ValueError(f\"Model not recognized: {model}\")\n",
    "# parse_agg_metrics_df = pd.DataFrame(parse_agg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_agg_metrics_df.loc[parse_agg_metrics_df[\"model\"] == \"sgnn0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_agg_metrics_df.sort_values(by=\"mse\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_agg_metrics_df.sort_values(by=\"mae\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_agg_metrics_df.loc[parse_agg_metrics_df[\"model\"].isin([\"sdne3\", \"sae\"])&(parse_agg_metrics_df[\"n_layers_enc\"] == \"1\")].sort_values(by=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(parse_agg_metrics_df.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define unique line styles and markers for each model, ensure there are enough styles for each model\n",
    "# styles = ['-', '--', '-.', ':']\n",
    "# markers = ['o', 's', 'X', 'D']\n",
    "\n",
    "# plt.figure(figsize=(8, 6))  # Create a figure for the plots\n",
    "\n",
    "# # Get the unique models\n",
    "# unique_models = all_metrics_by_true_cov_df[\"model\"].unique()\n",
    "\n",
    "# # Iterate through each unique model and plot on the same graph with a unique style\n",
    "# for idx, model in enumerate(unique_models):\n",
    "#     # Filter the DataFrame for the current model\n",
    "#     model_df = all_metrics_by_true_cov_df[all_metrics_by_true_cov_df[\"model\"] == model]\n",
    "    \n",
    "#     # Plot the lineplot on the same figure with unique style and marker\n",
    "#     sns.lineplot(\n",
    "#         x='cov', y='mse', data=model_df,\n",
    "#         label=model, linestyle=styles[idx % len(styles)], marker=markers[idx % len(markers)]\n",
    "#     )\n",
    "\n",
    "# plt.title('MSE by Correlation across Models')  # Set the title for the entire plot\n",
    "# plt.xlabel('Correlation')  # Set the x-axis label\n",
    "# plt.ylabel('MSE')  # Set the y-axis label\n",
    "# plt.legend(title='Model')  # Enable the legend to distinguish models\n",
    "\n",
    "# # Rotate x labels for better fit\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# # Adjust the layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define unique line styles and markers for each model, ensure there are enough styles for each model\n",
    "# styles = ['-', '--', '-.', ':']\n",
    "# markers = ['o', 's', 'X', 'D']\n",
    "\n",
    "# plt.figure(figsize=(8, 6))  # Create a figure for the plots\n",
    "\n",
    "# # Get the unique models\n",
    "# unique_models = all_metrics_by_true_cov_df[\"model\"].unique()\n",
    "\n",
    "# # Iterate through each unique model and plot on the same graph with a unique style\n",
    "# for idx, model in enumerate(unique_models):\n",
    "#     # Filter the DataFrame for the current model\n",
    "#     model_df = all_metrics_by_true_cov_df[all_metrics_by_true_cov_df[\"model\"] == model]\n",
    "    \n",
    "#     # Plot the lineplot on the same figure with unique style and marker\n",
    "#     sns.lineplot(\n",
    "#         x='cov', y='mae', data=model_df,\n",
    "#         label=model, linestyle=styles[idx % len(styles)], marker=markers[idx % len(markers)]\n",
    "#     )\n",
    "\n",
    "# plt.title('MAE by Correlation across Models')  # Set the title for the entire plot\n",
    "# plt.xlabel('Correlation')  # Set the x-axis label\n",
    "# plt.ylabel('MAE')  # Set the y-axis label\n",
    "# plt.legend(title='Model')  # Enable the legend to distinguish models\n",
    "\n",
    "# # Rotate x labels for better fit\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# # Adjust the layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in all_diff_by_true_cov_df[\"model\"].unique():\n",
    "#     model_df = all_diff_by_true_cov_df[all_diff_by_true_cov_df[\"model\"] == model]\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.boxplot(x=\"true\", y=\"pred\", data=model_df)\n",
    "#     plt.title(f'Predicted value for the model {model}')\n",
    "#     plt.xlabel('True Correlation value')\n",
    "#     plt.ylabel('Predicted')\n",
    "#     plt.xticks(rotation=45, ha='right')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation 1b\n",
    "\n",
    "### Dataset\n",
    "\n",
    "For each covariance in a list of different covariances between graph pairs, for n in a list of the number of nodes (10 to 100, 10 by 10), we simulate 30 times (n_simulations) a list of 50 (n_graphs) pairs of graphs from the erdos-renyi family of graphs. For each pair of graph, we sample a random variable p from a multivariate gaussian distribution with fixed mean and covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = \"simulation1a\"\n",
    "# n_nodes = os.listdir(os.path.join(outputs_path, dataset))\n",
    "# n_nodes_agg_metrics = []\n",
    "# for n in n_nodes:\n",
    "#     models = os.listdir(os.path.join(outputs_path, dataset, n))\n",
    "#     for model in models:\n",
    "\n",
    "#         # load data\n",
    "#         data = load_pickle(os.path.join(outputs_path, dataset, n, model, 'results.pkl'))\n",
    "\n",
    "#         try:\n",
    "#             if model == 'spectrum':\n",
    "#                 test_data = data[\"train_test_results\"]\n",
    "#             else:\n",
    "#                 test_data = data[\"test_results\"]\n",
    "#         except:\n",
    "#             print(model, n)\n",
    "\n",
    "#         test_data_df = []\n",
    "#         for i in range(test_data.shape[0]):\n",
    "#             simulation_test_data = test_data[i, :, :]\n",
    "#             simulation_test_data_df = pd.DataFrame(simulation_test_data.numpy(), columns=[\"pred\", \"true\"])\n",
    "#             simulation_test_data_df.loc[:, \"simulation\"] = i\n",
    "\n",
    "#             test_data_df.append(simulation_test_data_df)\n",
    "#         test_data_df = pd.concat(test_data_df, axis=0)\n",
    "#         test_data_df.loc[:, \"true\"] = [round(x, 2) for x in test_data_df[\"true\"]]\n",
    "#         test_data_df.loc[:, \"model\"] = model\n",
    "#         all_test_data.append(test_data_df)\n",
    "\n",
    "#         # compute aggregated mse and mae\n",
    "#         mse = mean_squared_error(test_data_df[\"true\"], test_data_df[\"pred\"])\n",
    "#         mae = mean_absolute_error(test_data_df[\"true\"], test_data_df[\"pred\"])\n",
    "#         n_nodes_agg_metrics.append({\"model\": model, \"n_nodes\": n, \"mse\": mse, \"mae\": mae})\n",
    "# n_nodes_agg_metrics_df = pd.DataFrame(n_nodes_agg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_nodes_agg_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = ['red', 'green', 'blue', 'purple']  # Define a color for each line\n",
    "\n",
    "# plt.figure(figsize=(8, 6))  # Create a figure for the plots\n",
    "\n",
    "# sns.lineplot(data=n_nodes_agg_metrics_df, x=\"n_nodes\", y=\"mse\", hue=\"model\")\n",
    "\n",
    "# plt.title('MSE as a Function of the Number of Nodes')  # Set the title for the entire plot\n",
    "# plt.xlabel('Number of nodes in the graph')  # Set the x-axis label\n",
    "# plt.ylabel('MSE')  # Set the y-axis label\n",
    "# plt.legend(title='Model')  # Enable the legend to distinguish models\n",
    "\n",
    "# # Rotate x labels for better fit\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# # Adjust the layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/danielco/miniconda3/envs/gce/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>simulation</th>\n",
       "      <th>model</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>watts_strogatz</td>\n",
       "      <td>sdne9_50_1_1_10</td>\n",
       "      <td>0.335210</td>\n",
       "      <td>0.500083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>watts_strogatz</td>\n",
       "      <td>sdne8_100_1_1_200</td>\n",
       "      <td>0.328972</td>\n",
       "      <td>0.495722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>watts_strogatz</td>\n",
       "      <td>sdne9_50_1_1_100</td>\n",
       "      <td>0.335268</td>\n",
       "      <td>0.500399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>watts_strogatz</td>\n",
       "      <td>sdne8_50_1_1_100_alpha1_beta1_gamma1_nu0</td>\n",
       "      <td>0.514668</td>\n",
       "      <td>0.590721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>watts_strogatz</td>\n",
       "      <td>sdne8_50_1_1_100</td>\n",
       "      <td>0.329044</td>\n",
       "      <td>0.491965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>watts_strogatz</td>\n",
       "      <td>sdne8_100_1_1_100</td>\n",
       "      <td>0.332854</td>\n",
       "      <td>0.498456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>watts_strogatz</td>\n",
       "      <td>sdne8_50_1_1_200_alpha1_beta1_gamma1_nu1</td>\n",
       "      <td>0.344008</td>\n",
       "      <td>0.505725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>watts_strogatz</td>\n",
       "      <td>sdne8_50_1_1_200_alpha1_beta1_gamma1_nu2</td>\n",
       "      <td>0.350792</td>\n",
       "      <td>0.508529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>watts_strogatz</td>\n",
       "      <td>sdne8_100_1_1_10</td>\n",
       "      <td>0.335484</td>\n",
       "      <td>0.500555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>watts_strogatz</td>\n",
       "      <td>spectrum</td>\n",
       "      <td>0.114484</td>\n",
       "      <td>0.269591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne9_50_1_1_10</td>\n",
       "      <td>0.221335</td>\n",
       "      <td>0.408035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne7_100_1_1_100</td>\n",
       "      <td>0.185448</td>\n",
       "      <td>0.373126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne9_50_1_1_100</td>\n",
       "      <td>0.271769</td>\n",
       "      <td>0.451327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne8_50_1_1_100_alpha1_beta1_gamma1_nu0</td>\n",
       "      <td>0.335982</td>\n",
       "      <td>0.500945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne8_50_1_1_100</td>\n",
       "      <td>0.039931</td>\n",
       "      <td>0.171013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne3_50_1_1_200</td>\n",
       "      <td>0.071028</td>\n",
       "      <td>0.231601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne7_100_1_1_10</td>\n",
       "      <td>0.214518</td>\n",
       "      <td>0.401020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne7_50_1_1_10</td>\n",
       "      <td>0.147875</td>\n",
       "      <td>0.333207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne8_50_1_1_200_alpha1_beta1_gamma1_nu1</td>\n",
       "      <td>0.374722</td>\n",
       "      <td>0.521131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne8_50_1_1_200_alpha1_beta1_gamma1_nu2</td>\n",
       "      <td>0.392767</td>\n",
       "      <td>0.529130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne7_50_1_1_100</td>\n",
       "      <td>0.253654</td>\n",
       "      <td>0.435840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>spectrum</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>0.080622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne3_50_1_1_100</td>\n",
       "      <td>0.044934</td>\n",
       "      <td>0.183730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne3_100_1_1_10</td>\n",
       "      <td>0.068724</td>\n",
       "      <td>0.225402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simulation1c</td>\n",
       "      <td>erdos_renyi</td>\n",
       "      <td>sdne3_50_1_1_10</td>\n",
       "      <td>0.071573</td>\n",
       "      <td>0.232589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset      simulation                                     model  \\\n",
       "0  simulation1c  watts_strogatz                           sdne9_50_1_1_10   \n",
       "0  simulation1c  watts_strogatz                         sdne8_100_1_1_200   \n",
       "0  simulation1c  watts_strogatz                          sdne9_50_1_1_100   \n",
       "0  simulation1c  watts_strogatz  sdne8_50_1_1_100_alpha1_beta1_gamma1_nu0   \n",
       "0  simulation1c  watts_strogatz                          sdne8_50_1_1_100   \n",
       "0  simulation1c  watts_strogatz                         sdne8_100_1_1_100   \n",
       "0  simulation1c  watts_strogatz  sdne8_50_1_1_200_alpha1_beta1_gamma1_nu1   \n",
       "0  simulation1c  watts_strogatz  sdne8_50_1_1_200_alpha1_beta1_gamma1_nu2   \n",
       "0  simulation1c  watts_strogatz                          sdne8_100_1_1_10   \n",
       "0  simulation1c  watts_strogatz                                  spectrum   \n",
       "0  simulation1c     erdos_renyi                           sdne9_50_1_1_10   \n",
       "0  simulation1c     erdos_renyi                         sdne7_100_1_1_100   \n",
       "0  simulation1c     erdos_renyi                          sdne9_50_1_1_100   \n",
       "0  simulation1c     erdos_renyi  sdne8_50_1_1_100_alpha1_beta1_gamma1_nu0   \n",
       "0  simulation1c     erdos_renyi                          sdne8_50_1_1_100   \n",
       "0  simulation1c     erdos_renyi                          sdne3_50_1_1_200   \n",
       "0  simulation1c     erdos_renyi                          sdne7_100_1_1_10   \n",
       "0  simulation1c     erdos_renyi                           sdne7_50_1_1_10   \n",
       "0  simulation1c     erdos_renyi  sdne8_50_1_1_200_alpha1_beta1_gamma1_nu1   \n",
       "0  simulation1c     erdos_renyi  sdne8_50_1_1_200_alpha1_beta1_gamma1_nu2   \n",
       "0  simulation1c     erdos_renyi                          sdne7_50_1_1_100   \n",
       "0  simulation1c     erdos_renyi                                  spectrum   \n",
       "0  simulation1c     erdos_renyi                          sdne3_50_1_1_100   \n",
       "0  simulation1c     erdos_renyi                          sdne3_100_1_1_10   \n",
       "0  simulation1c     erdos_renyi                           sdne3_50_1_1_10   \n",
       "\n",
       "        mse       mae  \n",
       "0  0.335210  0.500083  \n",
       "0  0.328972  0.495722  \n",
       "0  0.335268  0.500399  \n",
       "0  0.514668  0.590721  \n",
       "0  0.329044  0.491965  \n",
       "0  0.332854  0.498456  \n",
       "0  0.344008  0.505725  \n",
       "0  0.350792  0.508529  \n",
       "0  0.335484  0.500555  \n",
       "0  0.114484  0.269591  \n",
       "0  0.221335  0.408035  \n",
       "0  0.185448  0.373126  \n",
       "0  0.271769  0.451327  \n",
       "0  0.335982  0.500945  \n",
       "0  0.039931  0.171013  \n",
       "0  0.071028  0.231601  \n",
       "0  0.214518  0.401020  \n",
       "0  0.147875  0.333207  \n",
       "0  0.374722  0.521131  \n",
       "0  0.392767  0.529130  \n",
       "0  0.253654  0.435840  \n",
       "0  0.012156  0.080622  \n",
       "0  0.044934  0.183730  \n",
       "0  0.068724  0.225402  \n",
       "0  0.071573  0.232589  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"simulation1c\"\n",
    "simulation_names = os.listdir(os.path.join(outputs_path, dataset_name))\n",
    "\n",
    "all_metrics = []\n",
    "for simulation_name in simulation_names:\n",
    "\n",
    "\n",
    "    if \".DS_Store\" == simulation_name:\n",
    "        continue\n",
    "\n",
    "    for model in os.listdir(os.path.join(outputs_path, dataset_name, simulation_name)):\n",
    "\n",
    "        if \".DS_Store\" == model:\n",
    "            continue\n",
    "\n",
    "        if 'spectrum' in model:\n",
    "            data = load_pickle(os.path.join(outputs_path, dataset_name, simulation_name, model, 'results.pkl'))\n",
    "            test_data = data[\"train_test_results\"]\n",
    "        else:\n",
    "            data = load_pickle(os.path.join(outputs_path, dataset_name, simulation_name, model, 'predictions.pkl'))\n",
    "            test_data = data[\"test_predictions\"]\n",
    "\n",
    "        if len(test_data.shape) > 2:\n",
    "            test_data_df = []\n",
    "            for i in range(test_data.shape[0]):\n",
    "                simulation_test_data = test_data[i, :, :]\n",
    "                simulation_test_data_df = pd.DataFrame(simulation_test_data.cpu().numpy(), columns=[\"pred\", \"true\"])\n",
    "                simulation_test_data_df.loc[:, \"simulation\"] = i\n",
    "\n",
    "                test_data_df.append(simulation_test_data_df)\n",
    "            test_data_df = pd.concat(test_data_df, axis=0)\n",
    "            test_data_df.loc[:, \"true\"] = [round(x, 2) for x in test_data_df[\"true\"]]\n",
    "            test_data_df.loc[:, \"model\"] = model\n",
    "        else:\n",
    "            test_data_df = pd.DataFrame(test_data.numpy(), columns=[\"pred\", \"true\"])\n",
    "            test_data_df.loc[:, \"true\"] = [round(x, 2) for x in test_data_df[\"true\"]]\n",
    "            test_data_df.loc[:, \"model\"] = model\n",
    "\n",
    "\n",
    "        # compute aggregated mse and mae\n",
    "        mse = mean_squared_error(test_data_df[\"true\"], test_data_df[\"pred\"])\n",
    "        mae = mean_absolute_error(test_data_df[\"true\"], test_data_df[\"pred\"])\n",
    "\n",
    "        tmp_metrics = pd.DataFrame({\"dataset\": dataset_name,\n",
    "                                    \"simulation\": simulation_name,\n",
    "                                    \"model\": model,\n",
    "                                    \"mse\": mse,\n",
    "                                \"mae\": mae}, index=[0])\n",
    "        all_metrics.append(tmp_metrics)\n",
    "all_metrics_df = pd.concat(all_metrics, axis=0)\n",
    "\n",
    "all_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
